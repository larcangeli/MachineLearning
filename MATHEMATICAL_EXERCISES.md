# Mathematical Exercises for Linear Regression and Classification üßÆ

This document contains theoretical and mathematical exercises specifically designed for the linear regression and classification modules of the Machine Learning curriculum. These exercises complement the practical programming exercises in `EXERCISES.md` with mathematical derivations, theoretical analysis, and numerical applications.

---

## Linear Regression Exercises üìà

### Exercise LR-1: Gradient Descent for Linear Regression
**(5 marks)**

Consider a simple linear regression model with one feature: y = w‚ÇÅx + w‚ÇÄ, where w = [w‚ÇÄ, w‚ÇÅ]·µÄ are the parameters. Given the loss function:

J(w) = (1/2N) Œ£·µ¢‚Çå‚ÇÅ·¥∫ (w·µÄx·µ¢ - t·µ¢)¬≤

where x·µ¢ = [1, x·µ¢]·µÄ (augmented with bias term) and t·µ¢ is the target value.

1. **Derive the gradient** ‚àáJ(w) with respect to w. Show all steps. *(2 marks)*

2. **Write the gradient descent update rule** for both w‚ÇÄ and w‚ÇÅ with learning rate Œ∑. *(1 mark)*

3. **Apply the formula** to the following data with initial parameters w‚ÅΩ‚Å∞‚Åæ = [0.5, 1.0]·µÄ and learning rate Œ∑ = 0.1:
   - x‚ÇÅ = 2, t‚ÇÅ = 5
   - x‚ÇÇ = 3, t‚ÇÇ = 7
   
   Calculate w‚ÅΩ¬π‚Åæ after one iteration of batch gradient descent. *(2 marks)*

---

### Exercise LR-2: Ridge Regression Analysis
**(6 marks)**

Consider the ridge regression loss function:

J(w) = (1/2N) Œ£·µ¢‚Çå‚ÇÅ·¥∫ (w·µÄx·µ¢ - t·µ¢)¬≤ + (Œª/2)||w||¬≤

where Œª > 0 is the regularization parameter.

1. **Derive the gradient** ‚àáJ(w) including the regularization term. *(2 marks)*

2. **Find the closed-form solution** for the optimal weights w* by setting ‚àáJ(w*) = 0. Express your answer in matrix form. *(2 marks)*

3. **Numerical application**: Given the design matrix X and target vector t:
   ```
   X = [1  2]    t = [3]
       [1  4]        [5]
       [1  6]        [8]
   ```
   Calculate w* for Œª = 0.5. Show all matrix computations. *(2 marks)*

---

### Exercise LR-3: Convergence Analysis
**(4 marks)**

For the gradient descent algorithm applied to linear regression:

w·µè‚Å∫¬π = w·µè - Œ∑‚àáJ(w·µè)

where J(w) = (1/2N)||Xw - t||¬≤.

1. **Express the Hessian matrix** H = ‚àá¬≤J(w) in terms of X. *(1 mark)*

2. **State the condition** on the learning rate Œ∑ for guaranteed convergence in terms of the eigenvalues of H. *(1 mark)*

3. **For the matrix X from Exercise LR-2**, calculate the maximum eigenvalue of X·µÄX and determine the maximum learning rate that guarantees convergence. *(2 marks)*

---

## Linear Classification Exercises üéØ

### Exercise LC-1: Logistic Regression Derivation
**(6 marks)**

Consider binary logistic regression with the sigmoid function œÉ(z) = 1/(1 + e‚Åª·∂ª) and log-likelihood:

L(w) = Œ£·µ¢‚Çå‚ÇÅ·¥∫ [t·µ¢ log œÉ(w·µÄx·µ¢) + (1-t·µ¢) log(1-œÉ(w·µÄx·µ¢))]

where t·µ¢ ‚àà {0,1} are the binary labels.

1. **Show that** dœÉ(z)/dz = œÉ(z)(1-œÉ(z)). *(1 mark)*

2. **Derive the gradient** ‚àáL(w) with respect to w. Show all steps using the chain rule. *(3 marks)*

3. **Write the gradient ascent update rule** (since we maximize likelihood) for w with learning rate Œ∑. *(1 mark)*

4. **Apply to the data point** x = [1, 2, -1]·µÄ, t = 1, with current weights w = [0.1, 0.5, -0.2]·µÄ and Œ∑ = 0.3. Calculate the weight update. *(1 mark)*

---

### Exercise LC-2: Multiclass Classification
**(5 marks)**

For multiclass logistic regression with K classes, the softmax function is:

p(y = k|x, W) = exp(w‚Çñ·µÄx) / Œ£‚±º‚Çå‚ÇÅ·¥∑ exp(w‚±º·µÄx)

where W = [w‚ÇÅ, w‚ÇÇ, ..., w‚Çñ] is the weight matrix.

1. **Show that** Œ£‚Çñ‚Çå‚ÇÅ·¥∑ p(y = k|x, W) = 1. *(1 mark)*

2. **Derive the gradient** of the negative log-likelihood with respect to w‚Çñ for a single training example (x, t), where t is a one-hot encoded vector. *(3 marks)*

3. **For K = 3 classes**, given:
   - x = [1, 2]·µÄ
   - W = [0.1  0.3; 0.2  0.1; -0.1  0.2]
   - True class: t = [0, 1, 0]·µÄ
   
   Calculate the probability distribution and the gradient update for w‚ÇÇ. *(1 mark)*

---

### Exercise LC-3: Perceptron Algorithm Analysis
**(4 marks)**

The perceptron algorithm updates weights according to:

w‚ÅΩ·µó‚Å∫¬π‚Åæ = w‚ÅΩ·µó‚Åæ + Œ∑(t·µ¢ - ≈∑·µ¢)x·µ¢

where ≈∑·µ¢ = sign(w‚ÅΩ·µó‚Åæ·µÄx·µ¢) and t·µ¢ ‚àà {-1, +1}.

1. **Explain why** the perceptron only updates weights when there is a misclassification. *(1 mark)*

2. **Given the linearly separable dataset**:
   ```
   x‚ÇÅ = [1, 1]·µÄ,  t‚ÇÅ = +1
   x‚ÇÇ = [1, 2]·µÄ,  t‚ÇÇ = +1  
   x‚ÇÉ = [2, 1]·µÄ,  t‚ÇÉ = -1
   x‚ÇÑ = [2, 2]·µÄ,  t‚ÇÑ = -1
   ```
   
   Starting with w‚ÅΩ‚Å∞‚Åæ = [0, 0]·µÄ and Œ∑ = 1, perform 3 iterations through the dataset and show the weight updates. *(2 marks)*

3. **State the perceptron convergence theorem** and explain what it guarantees about the algorithm's behavior on linearly separable data. *(1 mark)*

---

### Exercise LC-4: Decision Boundaries and Regularization
**(6 marks)**

Consider logistic regression with L2 regularization:

J(w) = -Œ£·µ¢‚Çå‚ÇÅ·¥∫ [t·µ¢ log œÉ(w·µÄx·µ¢) + (1-t·µ¢) log(1-œÉ(w·µÄx·µ¢))] + (Œª/2)||w||¬≤

1. **Derive the regularized gradient** ‚àáJ(w). *(2 marks)*

2. **For 2D input (x‚ÇÅ, x‚ÇÇ) with bias**, write the equation of the decision boundary where p(y=1|x) = 0.5. *(1 mark)*

3. **Given the regularized logistic regression model** with weights w = [w‚ÇÄ, w‚ÇÅ, w‚ÇÇ]·µÄ = [1, -2, 3]·µÄ:
   - Find the decision boundary equation
   - Classify the points: A = [1, 1]·µÄ, B = [2, 0]·µÄ
   - Calculate the predicted probabilities for both points *(3 marks)*

---

## Advanced Integration Exercises üîó

### Exercise ADV-1: Comparing Regression and Classification
**(5 marks)**

Consider the same dataset used for both regression and classification tasks:

```
x‚ÇÅ = 1, y‚ÇÅ = 0.8    (regression target) / t‚ÇÅ = 1 (classification label)
x‚ÇÇ = 2, y‚ÇÇ = 0.3    (regression target) / t‚ÇÇ = 0 (classification label)  
x‚ÇÉ = 3, y‚ÇÉ = 0.1    (regression target) / t‚ÇÉ = 0 (classification label)
```

1. **Fit a linear regression** model y = w‚ÇÅx + w‚ÇÄ using least squares. Calculate w‚ÇÄ and w‚ÇÅ. *(2 marks)*

2. **Fit a logistic regression** model using the same x values but binary labels t. Set up the likelihood equations (you don't need to solve numerically). *(2 marks)*

3. **Compare the decision-making process**: At what value of x would the linear regression predict y = 0.5? How does this compare to the logistic regression decision boundary? *(1 mark)*

---

### Exercise ADV-2: Optimization Comparison
**(4 marks)**

Compare gradient descent behavior for linear regression vs. logistic regression:

1. **Explain why** the linear regression cost function J(w) = (1/2N)||Xw - t||¬≤ is convex, while discussing the convexity of the logistic regression cost function. *(2 marks)*

2. **For identical datasets and identical initial weights**, would you expect gradient descent to converge faster for linear or logistic regression? Justify your answer by comparing the nature of their gradients. *(2 marks)*

---

## Solutions Guide üìù

### Tips for Solving These Exercises:

1. **Always start with the basic definitions** - understand what each symbol represents
2. **Use the chain rule systematically** - break down complex derivatives into manageable parts  
3. **Check your dimensions** - ensure matrix multiplications are valid
4. **Verify special cases** - test your formulas with simple examples
5. **Connect theory to practice** - relate mathematical results to algorithm behavior

### Key Formulas to Remember:

- **Linear Regression Gradient**: ‚àáJ(w) = (1/N)X·µÄ(Xw - t)
- **Logistic Regression Gradient**: ‚àáL(w) = X·µÄ(t - œÉ(Xw))
- **Ridge Regularization**: Add Œªw to the gradient
- **Sigmoid Derivative**: œÉ'(z) = œÉ(z)(1 - œÉ(z))

---

## Sample Solution: Exercise LR-1
*(Provided as an example of expected solution format)*

**Exercise LR-1: Gradient Descent for Linear Regression**

**Part 1: Derive the gradient ‚àáJ(w)**

Given: J(w) = (1/2N) Œ£·µ¢‚Çå‚ÇÅ·¥∫ (w·µÄx·µ¢ - t·µ¢)¬≤

Step 1: Expand the squared term
J(w) = (1/2N) Œ£·µ¢‚Çå‚ÇÅ·¥∫ [(w·µÄx·µ¢)¬≤ - 2w·µÄx·µ¢t·µ¢ + t·µ¢¬≤]

Step 2: Take partial derivative with respect to w
‚àÇJ/‚àÇw = (1/2N) Œ£·µ¢‚Çå‚ÇÅ·¥∫ [2w·µÄx·µ¢ ¬∑ x·µ¢ - 2t·µ¢x·µ¢]
      = (1/N) Œ£·µ¢‚Çå‚ÇÅ·¥∫ [w·µÄx·µ¢x·µ¢ - t·µ¢x·µ¢]
      = (1/N) Œ£·µ¢‚Çå‚ÇÅ·¥∫ x·µ¢(w·µÄx·µ¢ - t·µ¢)

Therefore: **‚àáJ(w) = (1/N) Œ£·µ¢‚Çå‚ÇÅ·¥∫ x·µ¢(w·µÄx·µ¢ - t·µ¢)**

**Part 2: Gradient descent update rule**

**w‚ÅΩ·µè‚Å∫¬π‚Åæ = w‚ÅΩ·µè‚Åæ - Œ∑‚àáJ(w‚ÅΩ·µè‚Åæ)**

For individual components:
- **w‚ÇÄ‚ÅΩ·µè‚Å∫¬π‚Åæ = w‚ÇÄ‚ÅΩ·µè‚Åæ - Œ∑(1/N) Œ£·µ¢‚Çå‚ÇÅ·¥∫ (w‚ÅΩ·µè‚Åæ·µÄx·µ¢ - t·µ¢)**
- **w‚ÇÅ‚ÅΩ·µè‚Å∫¬π‚Åæ = w‚ÇÅ‚ÅΩ·µè‚Åæ - Œ∑(1/N) Œ£·µ¢‚Çå‚ÇÅ·¥∫ (w‚ÅΩ·µè‚Åæ·µÄx·µ¢ - t·µ¢)x·µ¢**

**Part 3: Numerical application**

Given: w‚ÅΩ‚Å∞‚Åæ = [0.5, 1.0]·µÄ, Œ∑ = 0.1, N = 2
- Point 1: x‚ÇÅ = [1, 2]·µÄ, t‚ÇÅ = 5
- Point 2: x‚ÇÇ = [1, 3]·µÄ, t‚ÇÇ = 7

Step 1: Calculate predictions
- ≈∑‚ÇÅ = w‚ÅΩ‚Å∞‚Åæ·µÄx‚ÇÅ = 0.5(1) + 1.0(2) = 2.5
- ≈∑‚ÇÇ = w‚ÅΩ‚Å∞‚Åæ·µÄx‚ÇÇ = 0.5(1) + 1.0(3) = 3.5

Step 2: Calculate errors
- e‚ÇÅ = ≈∑‚ÇÅ - t‚ÇÅ = 2.5 - 5 = -2.5
- e‚ÇÇ = ≈∑‚ÇÇ - t‚ÇÇ = 3.5 - 7 = -3.5

Step 3: Calculate gradient
‚àáJ(w‚ÅΩ‚Å∞‚Åæ) = (1/2)[x‚ÇÅe‚ÇÅ + x‚ÇÇe‚ÇÇ]
         = (1/2)[[1, 2]·µÄ(-2.5) + [1, 3]·µÄ(-3.5)]
         = (1/2)[[-2.5, -5.0]·µÄ + [-3.5, -10.5]·µÄ]
         = (1/2)[-6.0, -15.5]·µÄ
         = [-3.0, -7.75]·µÄ

Step 4: Update weights
w‚ÅΩ¬π‚Åæ = w‚ÅΩ‚Å∞‚Åæ - Œ∑‚àáJ(w‚ÅΩ‚Å∞‚Åæ)
     = [0.5, 1.0]·µÄ - 0.1[-3.0, -7.75]·µÄ
     = [0.5, 1.0]·µÄ + [0.3, 0.775]·µÄ
     = **[0.8, 1.775]·µÄ**

---

*These exercises are designed to deepen your mathematical understanding of linear models in machine learning. Work through them systematically, and don't hesitate to review the theoretical foundations in the course PDFs.*